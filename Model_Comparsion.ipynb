{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a27d81",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-30T13:36:11.933247Z",
     "iopub.status.busy": "2025-03-30T13:36:11.932922Z",
     "iopub.status.idle": "2025-03-30T13:36:15.119012Z",
     "shell.execute_reply": "2025-03-30T13:36:15.118054Z"
    },
    "papermill": {
     "duration": 3.195262,
     "end_time": "2025-03-30T13:36:15.121329",
     "exception": false,
     "start_time": "2025-03-30T13:36:11.926067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/README\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/ivector/final.mat\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/ivector/online_cmvn.conf\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/ivector/splice.conf\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/ivector/final.dubm\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/ivector/global_cmvn.stats\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/conf/model.conf\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/conf/mfcc.conf\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/graph/HCLr.fst\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/graph/Gr.fst\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/graph/disambig_tid.int\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/graph/phones/word_boundary.int\n",
      "/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15/am/final.mdl\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/transcription.csv\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0116.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0063.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0114.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0107.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0172.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0101.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0186.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0180.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0001.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0163.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0164.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0297.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0032.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0183.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0269.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0144.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0021.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0097.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0132.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0016.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0320.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0164.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0034.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0110.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0187.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0029.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0060.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0176.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0211.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0163.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0332.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0203.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0223.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0017.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0141.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0289.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0123.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0229.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0213.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0318.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0330.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0306.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0067.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0138.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0142.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0324.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0291.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0108.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0312.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0011.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0005.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0166.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0283.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0052.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0064.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0153.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0115.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0159.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0119.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0264.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0103.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0019.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0012.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0308.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0208.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0101.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0136.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0274.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0040.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0122.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0302.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0124.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0022.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0054.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0036.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0082.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0002.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0094.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0169.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0185.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0003.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0066.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0026.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0275.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0020.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0192.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0171.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0059.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0080.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0151.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0024.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0257.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0043.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0141.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0168.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0010.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0175.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0009.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0117.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0011.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0137.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0162.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0147.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0029.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0158.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0121.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0042.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0077.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0117.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0071.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0085.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0065.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0157.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0037.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0260.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0328.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0323.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0259.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0127.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0047.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0184.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0321.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0151.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0036.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0007.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0195.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0125.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0126.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0046.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0002.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0061.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0167.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0225.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0282.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0191.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0331.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0207.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0140.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0171.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0013.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0069.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0137.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0009.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0005.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0073.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0001.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0079.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0120.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0272.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0144.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0276.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0216.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0010.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0251.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0145.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0254.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0143.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0120.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0311.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0165.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0221.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0105.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0140.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0139.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0224.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0081.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0273.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0064.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0169.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0008.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0050.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0053.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0090.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0197.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0161.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0135.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0056.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0148.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0071.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0174.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0113.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0314.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0058.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0206.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0012.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0067.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0127.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0130.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0218.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0193.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0179.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0135.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0305.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0153.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0112.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0119.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0070.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0168.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0194.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0100.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0298.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0130.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0129.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0285.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0039.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0024.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0175.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0014.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0154.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0095.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0128.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0105.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0159.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0065.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0030.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0092.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0133.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0156.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0268.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0088.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0081.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0296.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0066.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0309.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0181.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0242.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0098.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0076.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0107.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0049.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0182.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0239.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0300.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0091.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0338.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0128.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0230.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0021.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0023.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0233.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0317.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0074.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0270.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0017.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0108.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0085.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0281.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0014.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0284.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0214.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0077.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0149.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0004.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0327.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0051.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0055.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0125.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0205.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0062.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0170.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0003.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0155.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0134.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0263.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0052.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0304.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0121.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0032.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0236.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0047.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0099.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0006.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0013.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0295.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0134.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0248.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0037.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0096.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0245.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0007.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0058.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0072.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0057.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0252.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0156.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0237.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0288.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0326.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0255.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0094.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0204.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0095.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0178.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0041.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0160.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0246.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0136.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0185.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0226.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0028.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0139.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0174.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0146.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0028.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0069.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0322.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0183.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0068.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0056.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0041.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0038.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0313.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0152.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0016.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0337.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0249.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0256.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0131.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0044.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0307.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0031.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0033.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0096.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0240.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0023.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0124.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0316.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0118.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0113.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0008.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0031.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0091.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0162.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0109.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0336.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0241.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0039.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0299.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0179.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0209.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0294.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0212.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0132.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0048.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0333.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0315.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0098.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0142.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0097.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0018.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0286.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0247.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0150.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0182.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0051.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0155.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0258.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0078.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0072.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0220.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0087.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0227.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0186.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0188.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0084.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0228.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0061.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0146.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0180.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0035.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0215.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0038.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0152.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0027.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0170.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0111.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0123.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0196.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0092.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0238.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0073.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0110.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0025.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0015.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0253.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0177.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0234.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0154.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0202.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0060.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0161.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0062.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0074.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0057.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0250.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0131.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0020.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0231.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0266.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0019.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0329.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0084.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0044.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0199.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0068.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0267.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0034.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0149.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0049.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0118.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0045.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0150.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0027.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0148.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0048.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0271.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0050.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0111.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0088.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0006.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0167.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0025.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0078.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0177.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0093.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0089.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0278.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0261.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0287.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0129.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0176.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0018.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0319.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0015.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0030.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0158.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0109.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0279.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0099.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0244.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0310.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0033.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0166.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0219.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0210.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0083.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0292.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0075.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0222.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0301.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0181.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0042.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0102.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0079.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0106.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0093.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0232.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0043.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0147.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0100.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0334.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0262.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0198.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0080.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0190.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0104.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0082.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0173.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0076.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0145.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0075.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0103.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0070.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0160.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0086.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0189.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0173.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0157.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0133.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0054.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0143.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0335.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0004.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0243.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0126.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0114.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0089.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0059.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0040.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0184.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0138.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0325.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0201.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0026.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0172.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0087.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0200.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0293.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0178.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0090.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0055.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0046.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0112.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0280.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0083.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0277.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0290.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0053.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0045.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0265.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0165.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0235.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0106.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0035.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0086.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0303.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0116.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ001-0122.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0102.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0104.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0063.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0022.wav\n",
      "/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset/LJ002-0217.wav\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216af7cd",
   "metadata": {
    "papermill": {
     "duration": 0.005122,
     "end_time": "2025-03-30T13:36:15.132947",
     "exception": false,
     "start_time": "2025-03-30T13:36:15.127825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ***Whisper***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5113b61a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:36:15.143768Z",
     "iopub.status.busy": "2025-03-30T13:36:15.143377Z",
     "iopub.status.idle": "2025-03-30T13:36:39.557795Z",
     "shell.execute_reply": "2025-03-30T13:36:39.556693Z"
    },
    "papermill": {
     "duration": 24.421844,
     "end_time": "2025-03-30T13:36:39.559667",
     "exception": false,
     "start_time": "2025-03-30T13:36:15.137823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\r\n",
      "  Downloading openai-whisper-20240930.tar.gz (800 kB)\r\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\r\n",
      "Collecting jiwer\r\n",
      "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.67.1)\r\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\r\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.9.0)\r\n",
      "Collecting triton>=2.0.0 (from openai-whisper)\r\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Collecting click>=8.1.8 (from jiwer)\r\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\r\n",
      "  Downloading rapidfuzz-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2.4.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->openai-whisper) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->openai-whisper) (2024.2.0)\r\n",
      "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\r\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rapidfuzz-3.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\r\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803405 sha256=d90675b5094fd624244689ee5a261203a0c47568312a586aded8d0c3d1f9e504\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\r\n",
      "Successfully built openai-whisper\r\n",
      "Installing collected packages: triton, rapidfuzz, click, jiwer, openai-whisper\r\n",
      "  Attempting uninstall: click\r\n",
      "    Found existing installation: click 8.1.7\r\n",
      "    Uninstalling click-8.1.7:\r\n",
      "      Successfully uninstalled click-8.1.7\r\n",
      "Successfully installed click-8.1.8 jiwer-3.1.0 openai-whisper-20240930 rapidfuzz-3.12.2 triton-3.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-whisper pandas jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c98b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:36:39.580950Z",
     "iopub.status.busy": "2025-03-30T13:36:39.580580Z",
     "iopub.status.idle": "2025-03-30T13:36:48.487163Z",
     "shell.execute_reply": "2025-03-30T13:36:48.486351Z"
    },
    "papermill": {
     "duration": 8.918826,
     "end_time": "2025-03-30T13:36:48.488859",
     "exception": false,
     "start_time": "2025-03-30T13:36:39.570033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "import os\n",
    "import pandas as pd\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5d03ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:36:48.511483Z",
     "iopub.status.busy": "2025-03-30T13:36:48.511047Z",
     "iopub.status.idle": "2025-03-30T13:36:48.514662Z",
     "shell.execute_reply": "2025-03-30T13:36:48.513959Z"
    },
    "papermill": {
     "duration": 0.01637,
     "end_time": "2025-03-30T13:36:48.516028",
     "exception": false,
     "start_time": "2025-03-30T13:36:48.499658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUDIO_PATH = \"/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset\"\n",
    "CSV_PATH = \"/kaggle/input/english-audio-dataset-with-transcription/AI/transcription.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ad024e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:36:48.537343Z",
     "iopub.status.busy": "2025-03-30T13:36:48.537041Z",
     "iopub.status.idle": "2025-03-30T13:36:48.576621Z",
     "shell.execute_reply": "2025-03-30T13:36:48.575898Z"
    },
    "papermill": {
     "duration": 0.05198,
     "end_time": "2025-03-30T13:36:48.578282",
     "exception": false,
     "start_time": "2025-03-30T13:36:48.526302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH, delimiter=\"|\", names=[\"filename\", \"transcription\"])  \n",
    "df = df.set_index(\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60a56b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:36:48.599678Z",
     "iopub.status.busy": "2025-03-30T13:36:48.599413Z",
     "iopub.status.idle": "2025-03-30T13:37:01.991902Z",
     "shell.execute_reply": "2025-03-30T13:37:01.990987Z"
    },
    "papermill": {
     "duration": 13.40523,
     "end_time": "2025-03-30T13:37:01.993769",
     "exception": false,
     "start_time": "2025-03-30T13:36:48.588539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 461M/461M [00:07<00:00, 65.0MiB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "whisper_model = whisper.load_model(\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a2ae4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:37:02.023302Z",
     "iopub.status.busy": "2025-03-30T13:37:02.022923Z",
     "iopub.status.idle": "2025-03-30T13:42:40.113763Z",
     "shell.execute_reply": "2025-03-30T13:42:40.112789Z"
    },
    "papermill": {
     "duration": 338.107021,
     "end_time": "2025-03-30T13:42:40.115266",
     "exception": false,
     "start_time": "2025-03-30T13:37:02.008245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 523 audio files with Whisper...\n",
      " Processed 10/523 files...\n",
      " Processed 20/523 files...\n",
      " Processed 30/523 files...\n",
      " Processed 40/523 files...\n",
      " Processed 50/523 files...\n",
      " Processed 60/523 files...\n",
      " Processed 70/523 files...\n",
      " Processed 80/523 files...\n",
      " Processed 90/523 files...\n",
      " Processed 100/523 files...\n",
      " Processed 110/523 files...\n",
      " Processed 120/523 files...\n",
      " Processed 130/523 files...\n",
      " Processed 140/523 files...\n",
      " Processed 150/523 files...\n",
      " Processed 160/523 files...\n",
      " Processed 170/523 files...\n",
      " Processed 180/523 files...\n",
      " Processed 190/523 files...\n",
      " Processed 200/523 files...\n",
      " Processed 210/523 files...\n",
      " Processed 220/523 files...\n",
      " Processed 230/523 files...\n",
      " Processed 240/523 files...\n",
      " Processed 250/523 files...\n",
      " Processed 260/523 files...\n",
      " Processed 270/523 files...\n",
      " Processed 280/523 files...\n",
      " Processed 290/523 files...\n",
      " Processed 300/523 files...\n",
      " Processed 310/523 files...\n",
      " Processed 320/523 files...\n",
      " Processed 330/523 files...\n",
      " Processed 340/523 files...\n",
      " Processed 350/523 files...\n",
      " Processed 360/523 files...\n",
      " Processed 370/523 files...\n",
      " Processed 380/523 files...\n",
      " Processed 390/523 files...\n",
      " Processed 400/523 files...\n",
      " Processed 410/523 files...\n",
      " Processed 420/523 files...\n",
      " Processed 430/523 files...\n",
      " Processed 440/523 files...\n",
      " Processed 450/523 files...\n",
      " Processed 460/523 files...\n",
      " Processed 470/523 files...\n",
      " Processed 480/523 files...\n",
      " Processed 490/523 files...\n",
      " Processed 500/523 files...\n",
      " Processed 510/523 files...\n",
      " Processed 520/523 files...\n",
      " Transcriptions saved to /kaggle/working/whisper_transcriptions.csv\n",
      " Done! Processed 523 files.\n"
     ]
    }
   ],
   "source": [
    "AUDIO_PATH = \"/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset\"\n",
    "OUTPUT_CSV = \"/kaggle/working/whisper_transcriptions.csv\"\n",
    "transcriptions = []  # Store results\n",
    "\n",
    "#  Get total file count for progress tracking\n",
    "total_files = len([f for f in os.listdir(AUDIO_PATH) if f.endswith(\".wav\")])\n",
    "processed_count = 0  # Track progress\n",
    "\n",
    "print(f\" Processing {total_files} audio files with Whisper...\")\n",
    "\n",
    "#  Loop through all WAV files in the directory\n",
    "for file in os.listdir(AUDIO_PATH):\n",
    "    if file.endswith(\".wav\"):  # Process only WAV files\n",
    "        file_path = os.path.join(AUDIO_PATH, file)\n",
    "\n",
    "        #  Transcribe the audio file\n",
    "        result = whisper_model.transcribe(file_path)\n",
    "        transcribed_text = result[\"text\"].strip()  # Clean up whitespace\n",
    "\n",
    "        # Store result as a dictionary\n",
    "        transcriptions.append({\"filename\": file, \"whisper_transcription\": transcribed_text})\n",
    "\n",
    "        #  Progress Tracking\n",
    "        processed_count += 1\n",
    "        if processed_count % 10 == 0:  # Print progress every 10 files\n",
    "            print(f\" Processed {processed_count}/{total_files} files...\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "whisper_df = pd.DataFrame(transcriptions)\n",
    "\n",
    "#  Save results to CSV\n",
    "whisper_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\" Transcriptions saved to {OUTPUT_CSV}\")\n",
    "print(f\" Done! Processed {processed_count} files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7797aa7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:42:40.146440Z",
     "iopub.status.busy": "2025-03-30T13:42:40.146164Z",
     "iopub.status.idle": "2025-03-30T13:42:40.233371Z",
     "shell.execute_reply": "2025-03-30T13:42:40.232209Z"
    },
    "papermill": {
     "duration": 0.103766,
     "end_time": "2025-03-30T13:42:40.234735",
     "exception": false,
     "start_time": "2025-03-30T13:42:40.130969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Filenames Sample: ['lj001-0001', 'lj001-0002', 'lj001-0003', 'lj001-0004', 'lj001-0005', 'lj001-0006', 'lj001-0007', 'lj001-0008', 'lj001-0009', 'lj001-0010']\n",
      "Processed Whisper Filenames Sample: ['lj001-0116', 'lj001-0063', 'lj001-0114', 'lj001-0107', 'lj001-0172', 'lj001-0101', 'lj002-0186', 'lj001-0180', 'lj001-0001', 'lj001-0163']\n",
      "Merged Dataframe Shape: (523, 3)\n",
      "     filename       WER\n",
      "0  lj001-0001  0.074074\n",
      "1  lj001-0002  0.000000\n",
      "2  lj001-0003  0.083333\n",
      "3  lj001-0004  0.000000\n",
      "4  lj001-0005  0.080000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jiwer  # Library for computing WER\n",
    "\n",
    "# Load CSV files with correct separators\n",
    "ground_truth_df = pd.read_csv(\"/kaggle/input/english-audio-dataset-with-transcription/AI/transcription.csv\", \n",
    "                              sep=\"|\", header=None, names=[\"filename\", \"ground_truth_transcription\"])\n",
    "whisper_df = pd.read_csv(\"/kaggle/working/whisper_transcriptions.csv\")\n",
    "\n",
    "# Standardize filenames: strip spaces, convert to lowercase\n",
    "ground_truth_df[\"filename\"] = ground_truth_df[\"filename\"].astype(str).str.strip().str.lower()\n",
    "whisper_df[\"filename\"] = whisper_df[\"filename\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "#  Remove \".wav\" from whisper filenames\n",
    "whisper_df[\"filename\"] = whisper_df[\"filename\"].str.replace(\".wav\", \"\", regex=False)\n",
    "\n",
    "#  Debugging: Print sample filenames after processing\n",
    "print(\"Ground Truth Filenames Sample:\", ground_truth_df[\"filename\"].head(10).tolist())\n",
    "print(\"Processed Whisper Filenames Sample:\", whisper_df[\"filename\"].head(10).tolist())\n",
    "\n",
    "# Sort both dataframes by filename\n",
    "ground_truth_df = ground_truth_df.sort_values(by=\"filename\").reset_index(drop=True)\n",
    "whisper_df = whisper_df.sort_values(by=\"filename\").reset_index(drop=True)\n",
    "\n",
    "# Merge dataframes on filenames (should work now)\n",
    "merged_df = pd.merge(ground_truth_df, whisper_df, on=\"filename\", how=\"inner\")\n",
    "\n",
    "#  Check if merge is successful\n",
    "print(f\"Merged Dataframe Shape: {merged_df.shape}\")\n",
    "\n",
    "# Drop rows with missing values in transcriptions\n",
    "merged_df = merged_df.dropna(subset=[\"ground_truth_transcription\", \"whisper_transcription\"])\n",
    "\n",
    "# Function to compute WER safely\n",
    "def calculate_wer(row):\n",
    "    try:\n",
    "        return jiwer.wer(str(row[\"ground_truth_transcription\"]), str(row[\"whisper_transcription\"]))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {row['filename']}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Compute WER\n",
    "merged_df[\"WER\"] = merged_df.apply(calculate_wer, axis=1)\n",
    "\n",
    "# Display results\n",
    "print(merged_df[[\"filename\", \"WER\"]].head())\n",
    "\n",
    "# Save final CSV for analysis\n",
    "merged_df.to_csv(\"/kaggle/working/evaluation_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27f2ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:42:40.265478Z",
     "iopub.status.busy": "2025-03-30T13:42:40.265242Z",
     "iopub.status.idle": "2025-03-30T13:42:40.269587Z",
     "shell.execute_reply": "2025-03-30T13:42:40.268862Z"
    },
    "papermill": {
     "duration": 0.020372,
     "end_time": "2025-03-30T13:42:40.270755",
     "exception": false,
     "start_time": "2025-03-30T13:42:40.250383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall WER: 15.57%\n"
     ]
    }
   ],
   "source": [
    "# Compute the overall average WER\n",
    "overall_wer = merged_df[\"WER\"].mean()\n",
    "\n",
    "print(f\"Overall WER: {overall_wer:.2%}\")  # Display as percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a747fc89",
   "metadata": {
    "papermill": {
     "duration": 0.014209,
     "end_time": "2025-03-30T13:42:40.299766",
     "exception": false,
     "start_time": "2025-03-30T13:42:40.285557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ***Faster Whisper***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa86b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:42:40.329391Z",
     "iopub.status.busy": "2025-03-30T13:42:40.329099Z",
     "iopub.status.idle": "2025-03-30T13:42:53.794619Z",
     "shell.execute_reply": "2025-03-30T13:42:53.793464Z"
    },
    "papermill": {
     "duration": 13.48234,
     "end_time": "2025-03-30T13:42:53.796389",
     "exception": false,
     "start_time": "2025-03-30T13:42:40.314049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faster-whisper\r\n",
      "  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting ctranslate2<5,>=4.0 (from faster-whisper)\r\n",
      "  Downloading ctranslate2-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.29.0)\r\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.21.0)\r\n",
      "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\r\n",
      "  Downloading onnxruntime-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\r\n",
      "Collecting av>=11 (from faster-whisper)\r\n",
      "  Downloading av-14.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (4.67.1)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.1.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.4)\r\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.17.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2024.12.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.2)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.12.2)\r\n",
      "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.25)\r\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (2.4.1)\r\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2025.1.31)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->ctranslate2<5,>=4.0->faster-whisper) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (2024.2.0)\r\n",
      "Downloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading av-14.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.8 MB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ctranslate2-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading onnxruntime-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: humanfriendly, av, coloredlogs, onnxruntime, ctranslate2, faster-whisper\r\n",
      "Successfully installed av-14.2.0 coloredlogs-15.0.1 ctranslate2-4.5.0 faster-whisper-1.1.1 humanfriendly-10.0 onnxruntime-1.21.0\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84954b9f06dc4c7383434950a6e1ea02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.txt:   0%|          | 0.00/460k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cbf14cee9842dfaef3f4e9d618125c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f817f4c7c13e485ab2019048b62e3e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58005c280544221a39a0a00b638ed7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/484M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install faster-whisper\n",
    "from faster_whisper import WhisperModel  \n",
    "\n",
    "# Load Faster Whisper with CPU-only mode (lower memory usage)\n",
    "faster_whisper_model = WhisperModel(\"small\", device=\"cpu\", compute_type=\"int8\")  \n",
    " # Use float16 for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018aecfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:42:53.833245Z",
     "iopub.status.busy": "2025-03-30T13:42:53.832767Z",
     "iopub.status.idle": "2025-03-30T13:42:57.354951Z",
     "shell.execute_reply": "2025-03-30T13:42:57.353990Z"
    },
    "papermill": {
     "duration": 3.542638,
     "end_time": "2025-03-30T13:42:57.357340",
     "exception": false,
     "start_time": "2025-03-30T13:42:53.814702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.1.0)\r\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.8)\r\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.12.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer\n",
    "import os\n",
    "import pandas as pd\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f45d52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:42:57.392813Z",
     "iopub.status.busy": "2025-03-30T13:42:57.392537Z",
     "iopub.status.idle": "2025-03-30T13:42:57.395797Z",
     "shell.execute_reply": "2025-03-30T13:42:57.395232Z"
    },
    "papermill": {
     "duration": 0.022404,
     "end_time": "2025-03-30T13:42:57.397250",
     "exception": false,
     "start_time": "2025-03-30T13:42:57.374846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUDIO_PATH = \"/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset\"\n",
    "CSV_PATH = \"/kaggle/input/english-audio-dataset-with-transcription/AI/transcription.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52ac2aa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:42:57.431720Z",
     "iopub.status.busy": "2025-03-30T13:42:57.431464Z",
     "iopub.status.idle": "2025-03-30T13:42:57.458808Z",
     "shell.execute_reply": "2025-03-30T13:42:57.458040Z"
    },
    "papermill": {
     "duration": 0.0459,
     "end_time": "2025-03-30T13:42:57.460190",
     "exception": false,
     "start_time": "2025-03-30T13:42:57.414290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH, delimiter=\"|\", names=[\"filename\", \"transcription\"])  \n",
    "df = df.set_index(\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "589a9136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T13:42:57.494748Z",
     "iopub.status.busy": "2025-03-30T13:42:57.494531Z",
     "iopub.status.idle": "2025-03-30T14:55:06.647821Z",
     "shell.execute_reply": "2025-03-30T14:55:06.646888Z"
    },
    "papermill": {
     "duration": 4329.172201,
     "end_time": "2025-03-30T14:55:06.649202",
     "exception": false,
     "start_time": "2025-03-30T13:42:57.477001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 523 audio files...\n",
      " Processed 10/523 files...\n",
      " Processed 20/523 files...\n",
      " Processed 30/523 files...\n",
      " Processed 40/523 files...\n",
      " Processed 50/523 files...\n",
      " Processed 60/523 files...\n",
      " Processed 70/523 files...\n",
      " Processed 80/523 files...\n",
      " Processed 90/523 files...\n",
      " Processed 100/523 files...\n",
      " Processed 110/523 files...\n",
      " Processed 120/523 files...\n",
      " Processed 130/523 files...\n",
      " Processed 140/523 files...\n",
      " Processed 150/523 files...\n",
      " Processed 160/523 files...\n",
      " Processed 170/523 files...\n",
      " Processed 180/523 files...\n",
      " Processed 190/523 files...\n",
      " Processed 200/523 files...\n",
      " Processed 210/523 files...\n",
      " Processed 220/523 files...\n",
      " Processed 230/523 files...\n",
      " Processed 240/523 files...\n",
      " Processed 250/523 files...\n",
      " Processed 260/523 files...\n",
      " Processed 270/523 files...\n",
      " Processed 280/523 files...\n",
      " Processed 290/523 files...\n",
      " Processed 300/523 files...\n",
      " Processed 310/523 files...\n",
      " Processed 320/523 files...\n",
      " Processed 330/523 files...\n",
      " Processed 340/523 files...\n",
      " Processed 350/523 files...\n",
      " Processed 360/523 files...\n",
      " Processed 370/523 files...\n",
      " Processed 380/523 files...\n",
      " Processed 390/523 files...\n",
      " Processed 400/523 files...\n",
      " Processed 410/523 files...\n",
      " Processed 420/523 files...\n",
      " Processed 430/523 files...\n",
      " Processed 440/523 files...\n",
      " Processed 450/523 files...\n",
      " Processed 460/523 files...\n",
      " Processed 470/523 files...\n",
      " Processed 480/523 files...\n",
      " Processed 490/523 files...\n",
      " Processed 500/523 files...\n",
      " Processed 510/523 files...\n",
      " Processed 520/523 files...\n",
      " Transcriptions saved to /kaggle/working/faster_whisper_transcriptions.csv\n",
      " Done! Processed 523 files.\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_CSV = \"/kaggle/working/faster_whisper_transcriptions.csv\"\n",
    "transcriptions = []  # Store results\n",
    "\n",
    "#  Loop through all WAV files in the directory\n",
    "total_files = len([f for f in os.listdir(AUDIO_PATH) if f.endswith(\".wav\")])\n",
    "processed_count = 0  # Track progress\n",
    "\n",
    "print(f\" Processing {total_files} audio files...\")\n",
    "\n",
    "for file in os.listdir(AUDIO_PATH):\n",
    "    if file.endswith(\".wav\"):  # Process only WAV files\n",
    "        file_path = os.path.join(AUDIO_PATH, file)\n",
    "\n",
    "        #  Transcribe the audio file using Faster Whisper\n",
    "        segments, _ = faster_whisper_model.transcribe(file_path)\n",
    "        transcribed_text = \" \".join(segment.text for segment in segments)  # Combine segments\n",
    "\n",
    "        # Store result as a dictionary\n",
    "        transcriptions.append({\"filename\": file, \"whisper_transcription\": transcribed_text})\n",
    "\n",
    "        processed_count += 1\n",
    "        if processed_count % 10 == 0:  # Print progress every 10 files\n",
    "            print(f\" Processed {processed_count}/{total_files} files...\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "faster_whisper_df = pd.DataFrame(transcriptions)\n",
    "\n",
    "#  Save results to CSV\n",
    "faster_whisper_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\" Transcriptions saved to {OUTPUT_CSV}\")\n",
    "print(f\" Done! Processed {processed_count} files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08d540c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T14:55:06.688068Z",
     "iopub.status.busy": "2025-03-30T14:55:06.687823Z",
     "iopub.status.idle": "2025-03-30T14:55:06.773043Z",
     "shell.execute_reply": "2025-03-30T14:55:06.772072Z"
    },
    "papermill": {
     "duration": 0.10617,
     "end_time": "2025-03-30T14:55:06.775210",
     "exception": false,
     "start_time": "2025-03-30T14:55:06.669040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Filenames Sample: ['lj001-0001', 'lj001-0002', 'lj001-0003', 'lj001-0004', 'lj001-0005', 'lj001-0006', 'lj001-0007', 'lj001-0008', 'lj001-0009', 'lj001-0010']\n",
      "Processed Faster Whisper Filenames Sample: ['lj001-0116', 'lj001-0063', 'lj001-0114', 'lj001-0107', 'lj001-0172', 'lj001-0101', 'lj002-0186', 'lj001-0180', 'lj001-0001', 'lj001-0163']\n",
      "Merged Dataframe Shape: (523, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jiwer\n",
    "ground_truth_df = pd.read_csv(\"/kaggle/input/english-audio-dataset-with-transcription/AI/transcription.csv\", \n",
    "                              sep=\"|\", header=None, names=[\"filename\", \"ground_truth_transcription\"])\n",
    "faster_whisper_df = pd.read_csv(OUTPUT_CSV)\n",
    "\n",
    "#  Standardize filenames: strip spaces, convert to lowercase\n",
    "ground_truth_df[\"filename\"] = ground_truth_df[\"filename\"].astype(str).str.strip().str.lower()\n",
    "faster_whisper_df[\"filename\"] = faster_whisper_df[\"filename\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "#  Remove \".wav\" from Faster Whisper filenames\n",
    "faster_whisper_df[\"filename\"] = faster_whisper_df[\"filename\"].str.replace(\".wav\", \"\", regex=False)\n",
    "\n",
    "#  Debugging: Print sample filenames\n",
    "print(\"Ground Truth Filenames Sample:\", ground_truth_df[\"filename\"].head(10).tolist())\n",
    "print(\"Processed Faster Whisper Filenames Sample:\", faster_whisper_df[\"filename\"].head(10).tolist())\n",
    "\n",
    "#  Sort both dataframes by filename\n",
    "ground_truth_df = ground_truth_df.sort_values(by=\"filename\").reset_index(drop=True)\n",
    "faster_whisper_df = faster_whisper_df.sort_values(by=\"filename\").reset_index(drop=True)\n",
    "\n",
    "#  Merge DataFrames on filename\n",
    "merged_df = pd.merge(ground_truth_df, faster_whisper_df, on=\"filename\", how=\"inner\")\n",
    "\n",
    "#  Check if merge is successful\n",
    "print(f\"Merged Dataframe Shape: {merged_df.shape}\")\n",
    "\n",
    "#  Drop rows with missing values in transcriptions\n",
    "merged_df = merged_df.dropna(subset=[\"ground_truth_transcription\", \"whisper_transcription\"])\n",
    "\n",
    "# Function to compute WER safely\n",
    "def calculate_wer(row):\n",
    "    try:\n",
    "        return jiwer.wer(str(row[\"ground_truth_transcription\"]), str(row[\"whisper_transcription\"]))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {row['filename']}: {e}\")\n",
    "        return None\n",
    "\n",
    "#  Compute WER for Faster Whisper\n",
    "merged_df[\"WER\"] = merged_df.apply(calculate_wer, axis=1)\n",
    "\n",
    "#  Save final evaluation results\n",
    "merged_df.to_csv(\"/kaggle/working/faster_whisper_evaluation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bda85fd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T14:55:06.820951Z",
     "iopub.status.busy": "2025-03-30T14:55:06.820708Z",
     "iopub.status.idle": "2025-03-30T14:55:06.824950Z",
     "shell.execute_reply": "2025-03-30T14:55:06.824236Z"
    },
    "papermill": {
     "duration": 0.024656,
     "end_time": "2025-03-30T14:55:06.826047",
     "exception": false,
     "start_time": "2025-03-30T14:55:06.801391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall WER for Faster Whisper: 15.63%\n"
     ]
    }
   ],
   "source": [
    "overall_wer = merged_df[\"WER\"].mean()\n",
    "print(f\"Overall WER for Faster Whisper: {overall_wer:.2%}\")  # Display as percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671bb86d",
   "metadata": {
    "papermill": {
     "duration": 0.019822,
     "end_time": "2025-03-30T14:55:06.865031",
     "exception": false,
     "start_time": "2025-03-30T14:55:06.845209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ***Vosk***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7559f32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T14:55:06.917598Z",
     "iopub.status.busy": "2025-03-30T14:55:06.917354Z",
     "iopub.status.idle": "2025-03-30T14:55:13.426239Z",
     "shell.execute_reply": "2025-03-30T14:55:13.425234Z"
    },
    "papermill": {
     "duration": 6.536406,
     "end_time": "2025-03-30T14:55:13.427937",
     "exception": false,
     "start_time": "2025-03-30T14:55:06.891531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vosk\r\n",
      "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.17.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.67.1)\r\n",
      "Collecting srt (from vosk)\r\n",
      "  Downloading srt-3.5.3.tar.gz (28 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from vosk) (14.1)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.22)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2025.1.31)\r\n",
      "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\r\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: srt\r\n",
      "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=6dfbc6a93c78b8be4548c4c0d979f4545e442e2d0a56b0ed76767958f348087c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\r\n",
      "Successfully built srt\r\n",
      "Installing collected packages: srt, vosk\r\n",
      "Successfully installed srt-3.5.3 vosk-0.3.45\r\n"
     ]
    }
   ],
   "source": [
    "!pip install vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3bef3ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T14:55:13.471873Z",
     "iopub.status.busy": "2025-03-30T14:55:13.471563Z",
     "iopub.status.idle": "2025-03-30T14:55:15.554327Z",
     "shell.execute_reply": "2025-03-30T14:55:15.553426Z"
    },
    "papermill": {
     "duration": 2.106127,
     "end_time": "2025-03-30T14:55:15.555968",
     "exception": false,
     "start_time": "2025-03-30T14:55:13.449841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import jiwer  # Library for computing WER\n",
    "import wave\n",
    "import vosk\n",
    "\n",
    "#  Load the Vosk model (Make sure you've downloaded a Vosk model and set the correct path)\n",
    "VOSK_MODEL_PATH = \"/kaggle/input/vosk-model-small-en-us-0-15/vosk-model-small-en-us-0.15\"\n",
    "vosk_model = vosk.Model(VOSK_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa2c9200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T14:55:15.600279Z",
     "iopub.status.busy": "2025-03-30T14:55:15.599950Z",
     "iopub.status.idle": "2025-03-30T15:07:11.285273Z",
     "shell.execute_reply": "2025-03-30T15:07:11.284216Z"
    },
    "papermill": {
     "duration": 715.708738,
     "end_time": "2025-03-30T15:07:11.286792",
     "exception": false,
     "start_time": "2025-03-30T14:55:15.578054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing 523 audio files with Vosk...\n",
      " Processed 10/523 files...\n",
      " Processed 20/523 files...\n",
      " Processed 30/523 files...\n",
      " Processed 40/523 files...\n",
      " Processed 50/523 files...\n",
      " Processed 60/523 files...\n",
      " Processed 70/523 files...\n",
      " Processed 80/523 files...\n",
      " Processed 90/523 files...\n",
      " Processed 100/523 files...\n",
      " Processed 110/523 files...\n",
      " Processed 120/523 files...\n",
      " Processed 130/523 files...\n",
      " Processed 140/523 files...\n",
      " Processed 150/523 files...\n",
      " Processed 160/523 files...\n",
      " Processed 170/523 files...\n",
      " Processed 180/523 files...\n",
      " Processed 190/523 files...\n",
      " Processed 200/523 files...\n",
      " Processed 210/523 files...\n",
      " Processed 220/523 files...\n",
      " Processed 230/523 files...\n",
      " Processed 240/523 files...\n",
      " Processed 250/523 files...\n",
      " Processed 260/523 files...\n",
      " Processed 270/523 files...\n",
      " Processed 280/523 files...\n",
      " Processed 290/523 files...\n",
      " Processed 300/523 files...\n",
      " Processed 310/523 files...\n",
      " Processed 320/523 files...\n",
      " Processed 330/523 files...\n",
      " Processed 340/523 files...\n",
      " Processed 350/523 files...\n",
      " Processed 360/523 files...\n",
      " Processed 370/523 files...\n",
      " Processed 380/523 files...\n",
      " Processed 390/523 files...\n",
      " Processed 400/523 files...\n",
      " Processed 410/523 files...\n",
      " Processed 420/523 files...\n",
      " Processed 430/523 files...\n",
      " Processed 440/523 files...\n",
      " Processed 450/523 files...\n",
      " Processed 460/523 files...\n",
      " Processed 470/523 files...\n",
      " Processed 480/523 files...\n",
      " Processed 490/523 files...\n",
      " Processed 500/523 files...\n",
      " Processed 510/523 files...\n",
      " Processed 520/523 files...\n",
      " Transcriptions saved to /kaggle/working/vosk_transcriptions.csv\n",
      " Done! Processed 523 files.\n"
     ]
    }
   ],
   "source": [
    "AUDIO_PATH = \"/kaggle/input/english-audio-dataset-with-transcription/AI/Dataset\"\n",
    "OUTPUT_CSV = \"/kaggle/working/vosk_transcriptions.csv\"\n",
    "transcriptions = []  # Store results\n",
    "\n",
    "#  Get total file count for progress tracking\n",
    "total_files = len([f for f in os.listdir(AUDIO_PATH) if f.endswith(\".wav\")])\n",
    "processed_count = 0  # Track progress\n",
    "\n",
    "print(f\" Processing {total_files} audio files with Vosk...\")\n",
    "\n",
    "#  Loop through all WAV files in the directory\n",
    "for file in os.listdir(AUDIO_PATH):\n",
    "    if file.endswith(\".wav\"):  # Process only WAV files\n",
    "        file_path = os.path.join(AUDIO_PATH, file)\n",
    "\n",
    "        #  Open the WAV file\n",
    "        with wave.open(file_path, \"rb\") as wf:\n",
    "            recognizer = vosk.KaldiRecognizer(vosk_model, wf.getframerate())\n",
    "\n",
    "            transcribed_text = \"\"\n",
    "            while True:\n",
    "                data = wf.readframes(4000)  # Read 4000 frames at a time\n",
    "                if len(data) == 0:\n",
    "                    break\n",
    "                if recognizer.AcceptWaveform(data):\n",
    "                    result = json.loads(recognizer.Result())\n",
    "                    transcribed_text += result.get(\"text\", \"\") + \" \"\n",
    "\n",
    "            # Get final result\n",
    "            final_result = json.loads(recognizer.FinalResult())\n",
    "            transcribed_text += final_result.get(\"text\", \"\")\n",
    "\n",
    "        # Store result as a dictionary\n",
    "        transcriptions.append({\"filename\": file, \"vosk_transcription\": transcribed_text.strip()})\n",
    "\n",
    "        #  Progress Tracking\n",
    "        processed_count += 1\n",
    "        if processed_count % 10 == 0:  # Print progress every 10 files\n",
    "            print(f\" Processed {processed_count}/{total_files} files...\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "vosk_df = pd.DataFrame(transcriptions)\n",
    "\n",
    "#  Save results to CSV\n",
    "vosk_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\" Transcriptions saved to {OUTPUT_CSV}\")\n",
    "print(f\" Done! Processed {processed_count} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "903d445a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T15:07:11.332478Z",
     "iopub.status.busy": "2025-03-30T15:07:11.332202Z",
     "iopub.status.idle": "2025-03-30T15:07:11.393034Z",
     "shell.execute_reply": "2025-03-30T15:07:11.391950Z"
    },
    "papermill": {
     "duration": 0.085157,
     "end_time": "2025-03-30T15:07:11.394519",
     "exception": false,
     "start_time": "2025-03-30T15:07:11.309362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Filenames Sample: ['lj001-0001', 'lj001-0002', 'lj001-0003', 'lj001-0004', 'lj001-0005', 'lj001-0006', 'lj001-0007', 'lj001-0008', 'lj001-0009', 'lj001-0010']\n",
      "Processed Vosk Filenames Sample: ['lj001-0116', 'lj001-0063', 'lj001-0114', 'lj001-0107', 'lj001-0172', 'lj001-0101', 'lj002-0186', 'lj001-0180', 'lj001-0001', 'lj001-0163']\n",
      "Merged Dataframe Shape: (523, 3)\n"
     ]
    }
   ],
   "source": [
    "ground_truth_df = pd.read_csv(\"/kaggle/input/english-audio-dataset-with-transcription/AI/transcription.csv\", \n",
    "                              sep=\"|\", header=None, names=[\"filename\", \"ground_truth_transcription\"])\n",
    "vosk_df = pd.read_csv(OUTPUT_CSV)\n",
    "\n",
    "#  Standardize filenames: strip spaces, convert to lowercase\n",
    "ground_truth_df[\"filename\"] = ground_truth_df[\"filename\"].astype(str).str.strip().str.lower()\n",
    "vosk_df[\"filename\"] = vosk_df[\"filename\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "#  Remove \".wav\" from Vosk filenames\n",
    "vosk_df[\"filename\"] = vosk_df[\"filename\"].str.replace(\".wav\", \"\", regex=False)\n",
    "\n",
    "#  Debugging: Print sample filenames\n",
    "print(\"Ground Truth Filenames Sample:\", ground_truth_df[\"filename\"].head(10).tolist())\n",
    "print(\"Processed Vosk Filenames Sample:\", vosk_df[\"filename\"].head(10).tolist())\n",
    "\n",
    "#  Sort both dataframes by filename\n",
    "ground_truth_df = ground_truth_df.sort_values(by=\"filename\").reset_index(drop=True)\n",
    "vosk_df = vosk_df.sort_values(by=\"filename\").reset_index(drop=True)\n",
    "\n",
    "#  Merge DataFrames on filename\n",
    "merged_df = pd.merge(ground_truth_df, vosk_df, on=\"filename\", how=\"inner\")\n",
    "\n",
    "#  Check if merge is successful\n",
    "print(f\"Merged Dataframe Shape: {merged_df.shape}\")\n",
    "\n",
    "#  Drop rows with missing values in transcriptions\n",
    "merged_df = merged_df.dropna(subset=[\"ground_truth_transcription\", \"vosk_transcription\"])\n",
    "\n",
    "# Function to compute WER safely\n",
    "def calculate_wer(row):\n",
    "    try:\n",
    "        return jiwer.wer(str(row[\"ground_truth_transcription\"]), str(row[\"vosk_transcription\"]))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {row['filename']}: {e}\")\n",
    "        return None\n",
    "\n",
    "#  Compute WER for Vosk\n",
    "merged_df[\"WER\"] = merged_df.apply(calculate_wer, axis=1)\n",
    "\n",
    "#  Save final evaluation results\n",
    "merged_df.to_csv(\"/kaggle/working/vosk_evaluation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e08c0489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T15:07:11.439052Z",
     "iopub.status.busy": "2025-03-30T15:07:11.438795Z",
     "iopub.status.idle": "2025-03-30T15:07:11.443503Z",
     "shell.execute_reply": "2025-03-30T15:07:11.442775Z"
    },
    "papermill": {
     "duration": 0.027844,
     "end_time": "2025-03-30T15:07:11.444713",
     "exception": false,
     "start_time": "2025-03-30T15:07:11.416869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall WER for Vosk: 29.38%\n"
     ]
    }
   ],
   "source": [
    "overall_wer = merged_df[\"WER\"].mean()\n",
    "print(f\"Overall WER for Vosk: {overall_wer:.2%}\")  # Display as percentage"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7001205,
     "sourceId": 11212245,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7003481,
     "sourceId": 11215370,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5466.544751,
   "end_time": "2025-03-30T15:07:14.595424",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-30T13:36:08.050673",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0fb24e743b7b4d96b52cd7af724b2524": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "158f419519f54a6faa6079076e83ed42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e14ae115c384c42a1d4497a9b17ebaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_abb181e6396946f397c7d169a2d273a7",
       "max": 2203239.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9528aa9f018448d69796d45a42aa421c",
       "tabbable": null,
       "tooltip": null,
       "value": 2203239.0
      }
     },
     "1e998ae514dd424ca0ba4dbadb8897ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e769cc7700da4caab5cc2fca95bcf9a9",
       "max": 483546902.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_92de647fe0e84a508bf9fff4871dd72a",
       "tabbable": null,
       "tooltip": null,
       "value": 483546902.0
      }
     },
     "22b98b6357f747eca597c3861e6fb416": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2682ffbf6416479bb9402521bb0f5ed5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "276e8192df6040eb8fb405f2194f749a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_158f419519f54a6faa6079076e83ed42",
       "placeholder": "",
       "style": "IPY_MODEL_8a772d45041a4ac0a32b7c746bab2dba",
       "tabbable": null,
       "tooltip": null,
       "value": "460k/460k[00:00&lt;00:00,5.07MB/s]"
      }
     },
     "2d2c6fe58b4d443b8dafa5047b7d7687": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "37cbf14cee9842dfaef3f4e9d618125c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ef0d885039b24d7dab50ad713a007a85",
        "IPY_MODEL_d56ede551dfe4248902bde49135ae34c",
        "IPY_MODEL_3d53c180fdd24d7c8a9a525d13acd49b"
       ],
       "layout": "IPY_MODEL_da0fd425c9ed4853be4fb4c40ae7a2b1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3ac37d41f8194c159830e4c1c06b4487": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d53c180fdd24d7c8a9a525d13acd49b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_71116f6936d042608f0f4c2c98f5814a",
       "placeholder": "",
       "style": "IPY_MODEL_a15ade654e3e4bbe9010cd901d244d15",
       "tabbable": null,
       "tooltip": null,
       "value": "2.37k/2.37k[00:00&lt;00:00,88.0kB/s]"
      }
     },
     "401a9785c1de4ed9baf8407acce28e44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "43398f09b8a74103932f0d3bbdcfc049": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4951089663284de391a210de182d5f7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_68d8a08c37e140a8b49681f4c39c572a",
       "placeholder": "",
       "style": "IPY_MODEL_aba9a6b455ef46d18de252c162b400ae",
       "tabbable": null,
       "tooltip": null,
       "value": "2.20M/2.20M[00:00&lt;00:00,23.9MB/s]"
      }
     },
     "56592384278a4505b54257332335da48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5de6c66ab74b4947960cd5e87d3c8bb8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6124b23e1ec9431197b7c083d80feae9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6667c71f808b43149efa2019f98f7961": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68511b4e5e2c4e78ae97f05cda78391f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_43398f09b8a74103932f0d3bbdcfc049",
       "placeholder": "",
       "style": "IPY_MODEL_89acf313576c45db8f6f9710f7aed6d2",
       "tabbable": null,
       "tooltip": null,
       "value": "vocabulary.txt:100%"
      }
     },
     "68d8a08c37e140a8b49681f4c39c572a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71116f6936d042608f0f4c2c98f5814a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82f7b76f835d449089cfc16be1e3ca74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f3d0b8c2505a4b00aeab865338525503",
       "max": 459861.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2d2c6fe58b4d443b8dafa5047b7d7687",
       "tabbable": null,
       "tooltip": null,
       "value": 459861.0
      }
     },
     "84954b9f06dc4c7383434950a6e1ea02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_68511b4e5e2c4e78ae97f05cda78391f",
        "IPY_MODEL_82f7b76f835d449089cfc16be1e3ca74",
        "IPY_MODEL_276e8192df6040eb8fb405f2194f749a"
       ],
       "layout": "IPY_MODEL_6667c71f808b43149efa2019f98f7961",
       "tabbable": null,
       "tooltip": null
      }
     },
     "89acf313576c45db8f6f9710f7aed6d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8a772d45041a4ac0a32b7c746bab2dba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "92de647fe0e84a508bf9fff4871dd72a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9528aa9f018448d69796d45a42aa421c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9ae4f9392fae425cb7339bfac0332f0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9f97acc4439c4e6c97b34daa3bcd2d88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3ac37d41f8194c159830e4c1c06b4487",
       "placeholder": "",
       "style": "IPY_MODEL_401a9785c1de4ed9baf8407acce28e44",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json:100%"
      }
     },
     "a15ade654e3e4bbe9010cd901d244d15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aba9a6b455ef46d18de252c162b400ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "abb181e6396946f397c7d169a2d273a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ca17621df3154b4ba6ceac5ad0beaad8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5de6c66ab74b4947960cd5e87d3c8bb8",
       "placeholder": "",
       "style": "IPY_MODEL_d83516d1d4b645e5901b398fa11e79a5",
       "tabbable": null,
       "tooltip": null,
       "value": "484M/484M[00:02&lt;00:00,264MB/s]"
      }
     },
     "cec179ba89c2440ca59a1d27529e2d5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d222f8d283c548e0adadcbe44d3d6be6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d56ede551dfe4248902bde49135ae34c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cec179ba89c2440ca59a1d27529e2d5a",
       "max": 2370.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_56592384278a4505b54257332335da48",
       "tabbable": null,
       "tooltip": null,
       "value": 2370.0
      }
     },
     "d58005c280544221a39a0a00b638ed7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_efa326ab71794d0b933a689d66089574",
        "IPY_MODEL_1e998ae514dd424ca0ba4dbadb8897ec",
        "IPY_MODEL_ca17621df3154b4ba6ceac5ad0beaad8"
       ],
       "layout": "IPY_MODEL_2682ffbf6416479bb9402521bb0f5ed5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d83516d1d4b645e5901b398fa11e79a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "da0fd425c9ed4853be4fb4c40ae7a2b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e769cc7700da4caab5cc2fca95bcf9a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef0d885039b24d7dab50ad713a007a85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6124b23e1ec9431197b7c083d80feae9",
       "placeholder": "",
       "style": "IPY_MODEL_0fb24e743b7b4d96b52cd7af724b2524",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "efa326ab71794d0b933a689d66089574": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d222f8d283c548e0adadcbe44d3d6be6",
       "placeholder": "",
       "style": "IPY_MODEL_9ae4f9392fae425cb7339bfac0332f0c",
       "tabbable": null,
       "tooltip": null,
       "value": "model.bin:100%"
      }
     },
     "f3d0b8c2505a4b00aeab865338525503": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f817f4c7c13e485ab2019048b62e3e60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9f97acc4439c4e6c97b34daa3bcd2d88",
        "IPY_MODEL_1e14ae115c384c42a1d4497a9b17ebaa",
        "IPY_MODEL_4951089663284de391a210de182d5f7c"
       ],
       "layout": "IPY_MODEL_22b98b6357f747eca597c3861e6fb416",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
